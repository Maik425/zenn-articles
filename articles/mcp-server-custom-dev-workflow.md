---
title: "自分たちのシステムに特化したMCPサーバーを作ったら、開発が本当に変わった話"
emoji: "🔌"
type: "idea"
topics: ["mcp", "claudecode", "開発効率化", "typescript", "postgresql"]
published: true
---

開発リードをやっている maiki です。

ここ最近で一番手応えがあった取り組みについて書く。自分たちが開発しているシステム EastFlow の専用 MCP サーバーを作ったら、Claude Code での開発体験がガラッと変わった、という話。

ひと言でまとめると、**コンテキストスイッチがめちゃくちゃ減った**。それだけで毎日の開発が明らかに楽になった。

## MCP サーバーを作ろうと思った経緯

まず MCP について。**MCP（Model Context Protocol）** は Anthropic が 2024 年 11 月にオープンソースとして公開した標準プロトコルで、AI モデルと外部ツールをつなぐための共通規格だ。2025 年には OpenAI や Google もサポートを表明しており、今では **AI ツール連携のデファクトスタンダード** になっている。

Claude 専用の仕組みではなく、業界全体で採用が進んでいるオープンな規格だと思ってもらえればいい。

Claude Code に MCP サーバーを接続すれば、チャットから直接 API やデータベースを叩けるようになる。

MCP の存在自体はなんとなく知っていた。でも正直「別になくても困らないだろ」くらいの認識だった。それが変わったのは、毎日のコーディング中に感じる小さなストレスが、じわじわ積み上がってきたからだ。

## コンテキストスイッチに殺される日々

EastFlow は Go + Next.js + PostgreSQL のスタック。日々のバグ修正や機能追加で、こんなパターンが何度も繰り返されていた。

1. Claude Code で「ユーザーテーブルのスキーマって何だっけ？」と聞く
2. Claude はデータベースに触れないので、pgAdmin か DBeaver を開いて自分で確認するしかない
3. pgAdmin をブラウザで開き、接続情報を入力し、テーブル一覧から該当テーブルを探す
4. スキーマを確認して、**コピーして Claude Code のチャットに貼り付ける**
5. やっと次の質問に進める

6. 「最新のユーザーデータを 10 件見てほしい」と頼むと、またpgAdmin を操作
7. データを確認して、また貼り付け
8. API エンドポイントのテストが必要になれば Postman か curl で試す

このサイクルが **1 時間の開発作業の中で 5 回、10 回と繰り返される**。

- pgAdmin / DBeaver のブラウザタブ
- Postman のウィンドウ
- Claude Code のターミナル
- コードエディタ

4 つ以上のアプリを行ったり来たり。これがコンテキストスイッチだ。タスクや環境を切り替えるたびに、脳の集中状態がリセットされる。

カリフォルニア大学の Gloria Mark 教授の研究によると、タスクを切り替えてから元の集中状態に戻るまで平均 23 分かかるとされている。1 時間に 5 回も切り替えていたら、まとまった集中時間なんてゼロに等しい。

そんな日々の中で、ふと思った。

**こんなの、Claude から直接叩けたらいいのに。**

## 作ったもの — EastFlow MCP サーバー

決断は早かった。毎日 Claude Code を使ってるんだから、自分たちのシステムに特化した MCP サーバーを作ろう、と。

TypeScript で書いた小さなサーバーで、機能はシンプルだけど開発で必要な操作は一通りカバーしている。

**主な機能**

1. **データベーススキーマの探索**
   - テーブル一覧を取得
   - 特定のテーブルの詳細（カラム名、型、制約、外部キー）を表示

2. **SQL クエリの実行**
   - SELECT でデータを確認
   - 書き込み操作は明示的な許可が必要にして、うっかりミスを防いでいる

3. **認証付き API 呼び出し**
   - EastFlow の API を叩くときに、JWT トークンを自動管理する。JWT とは Web API で広く使われるトークン認証の方式で、ログインしてトークンを取得し、期限切れ前に自動更新する処理を全部裏側でやってくれる

4. **SQL インジェクション対策**
   - パラメータ化クエリを使い、ユーザー入力がそのまま SQL として実行されるのを防止する。DROP や TRUNCATE のような破壊的な操作も自動で検出・ブロックする

実装の細かい話は技術ブログに譲る。ここで伝えたいのは、実際にどう使えるかだ。

## 日常が変わった 3 つのシーン

MCP サーバーをセットアップして Claude Code に接続した初日。半信半疑で試してみたら、感覚が一変した。

### シーン 1：スキーマ確認が一瞬

pgAdmin を開いてテーブルを探してカラム一覧をコピーして Claude Code に貼り付けて……で最低 2 分。それが、こうなった。

```
僕：「users テーブルのカラム構成を教えて」

Claude：（MCP で describe_table ツールを呼び出し）
「users テーブルの構成はこちらです：
 id (int8, NOT NULL), name (text, NOT NULL), email (text, NOT NULL)...
 外部キー: company_id -> companies.id」
```

ブラウザを開かなくていい。コピペもいらない。会話の流れのまま答えが返ってくる。

1 回のスキーマ確認で 2 分の節約。これが 1 日 15 回あれば **30 分の短縮** になる。それ以上に大きいのは、**集中が途切れない**こと。pgAdmin に切り替えて戻って、という動作がゼロになるだけで、1 時間あたりの体感的な開発時間が 15 分以上伸びた気がする。

### シーン 2：バグ調査が 5 分で終わる

ユーザーの登録フローで問題が起きているという報告をもらったときのこと。

以前なら、コードを読んで関係するテーブルを特定し、pgAdmin でそのテーブルを開き、該当レコードを検索し、スキーマを見直して、関連テーブルも確認して……という往復を繰り返す。体感で **30 分以上** はかかるパターンだ。

MCP がある今はこうだ。

```
僕：「user_id = 12345 のユーザーの登録状況を全テーブルで追跡して」

Claude：（MCP で users, user_profiles, registration_logs を順番に検索）
「追跡結果です。
 users テーブル -> 正常
 user_profiles -> 正常
 registration_logs -> ここが問題ですね。created_at のタイムスタンプが
 24時間ずれてます。タイムゾーンの設定を確認してください」
```

Claude がテーブルをまたいでデータを追いかけ、異常箇所を突き止めてくれた。**5 分で原因特定**。

30 分が 5 分に縮まるだけでなく、SQL の知識がなくても自然言語でデータを探せるので、チームの誰でもバグ調査に参加できるようになった。

### シーン 3：API テストがチャットだけで完結する

EastFlow の API に新しいエンドポイントを追加したとき。動作確認のために、従来なら Postman を起動して URL を入力して、認証ヘッダーに JWT トークンを設定して、リクエストボディを JSON で書いて送信……という手順が必要だった。

特に JWT トークンの取得が面倒で、先にログイン API を叩いてトークンをコピーし、それを別のリクエストのヘッダーに貼り付ける、という 2 段階の操作を毎回やっていた。

MCP なら：

```
僕：「/api/users/export エンドポイントを POST で実行して、
リクエストボディは { format: 'csv' } でお願い」

Claude：（MCP で api_request ツールを呼び出し。JWT は自動取得・管理）
「実行しました。
 POST /api/users/export -> 200 OK
 レスポンス: { status: 'processing', job_id: 'abc-123' }
 正常に動作しています」
```

認証も自動。リクエストも自然言語で指定。結果もチャットで確認。全部一箇所で完結する。

## 思わぬ副産物 — セーフティネット

作ってみて初めて気づいたのだが、この MCP サーバーが事故防止の仕組みとしても機能していた。

たとえば Claude に「このレコードを削除して」と雑に依頼しても、MCP サーバーが「書き込み操作は allow_write=true が必要です」とブロックしてくれる。`DELETE` に `WHERE` がなければ「WHERE 句なしの DELETE はブロックされました」と止める。

開発中にうっかり本番データを壊す事故を、構造的に防げるわけだ。

さらに、SQL インジェクション対策が組み込まれているので、Claude が生成する SQL にユーザー入力が含まれていても安全に処理される。`O'Brien` のように特殊文字を含む名前の検索でも、パラメータ化クエリが効いて問題なく動く。

セキュリティのためと思って入れた仕組みが、実際には開発中の人的ミスも防ぐ役割を果たしていた。一石二鳥だった。

## 課題 — 万能ではない

もちろん、何でも解決するわけではない。

**1. 権限管理**

MCP サーバーを複数人で使うなら、誰が何にアクセスできるかの管理が必要になる。今は小規模チームだから問題ないが、人が増えたら DB ユーザーの権限分離やアクセスログの監視を入れないといけない。

**2. 複雑なクエリには向かない**

何十行もの JOIN や EXPLAIN ANALYZE でチューニングが必要な場面では、素直に DBeaver を使ったほうが楽だ。MCP は日常業務の 80% を効率化するツールで、残り 20% の専門的な作業まで置き換えるものではない。

**3. ネットワーク環境**

MCP サーバーと DB の通信が増えるので、ネットワークが遅い環境ではもたつく可能性がある。ただしローカルで動かす分にはまったく気にならない。

## これから — 少しずつ育てていく

今はデータベースと API のアクセスだけだが、次のような機能を足していきたい。

- **ログの検索と分析** — アプリケーションログから特定のエラーを抽出して原因調査
- **デプロイメント情報** — 本番環境のバージョン確認やロールバック状況の把握
- **プロジェクト管理との連携** — GitHub Issues や Project の読み書き

ここが一番おもしろいところだと思っている。自分たちのワークフローに特化した MCP サーバーは、汎用ツールには絶対できないカスタマイズができる。公開されている汎用の PostgreSQL MCP サーバーもあるが、自社 API との連携やカスタム認証フローには対応していない。

自分たちの開発環境に合わせて少しずつ育てていく。開発アシスタントを自前で育てている感覚に近い。

## つなぐだけで、こんなに変わる

Claude のような AI と自分たちのシステムをつなぐ手段として、MCP というオープンな仕組みがある。

作るのに特別な難しさはなかった。TypeScript でいくつかのツールを定義して Claude Code に接続するだけ。1〜2 日で最初のバージョンが動いた。

それで得られたもの：

- **コンテキストスイッチの削減** — 1 日 30 分以上の時間節約
- **集中力の維持** — 途切れない開発フロー
- **セーフティネット** — うっかりミスの自動防止
- **チーム全体の底上げ** — SQL に詳しくないメンバーもデータ調査ができる

自分たちのシステムを持っていて Claude Code を日々使っているなら、専用の MCP サーバーを作るという選択肢は検討する価値がある。個人事業や小規模チームほど、ROI は高い。

自分たちの開発体験を自分たちで良くしていく。それができるのが今の時代のおもしろさだと思う。
