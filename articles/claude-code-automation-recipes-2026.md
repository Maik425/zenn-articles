---
title: "Claude Codeで実現する業務自動化 ― 小さい会社の5つの実践例"
emoji: "🔧"
type: "tech"
topics: ["claudecode", "python", "automation", "ai", "productivity"]
published: true
---

## 自動化は大企業だけの話じゃない

少人数のIT企業で働いている。開発、運用、営業、事務。人が少ないぶん、一人が何役もこなす。同じ作業を何度もやっていると、さすがにこれは自動化したいと思う場面が増えてくる。

ただ、業務自動化ってハードルが高く聞こえる。RPAツールは高い。SaaSを組み合わせればいけるが、Zapierの有料プランを複数契約すると月額がジワジワ効いてくる。自前でスクリプトを書けばいいが、書く時間がない。

そこでClaude Codeだ。

Claude Codeはターミナルで動くAIコーディングエージェントで、対話しながらコードを書いて実行してくれる。自分が業務の流れを口で説明すれば、Pythonスクリプトやシェルコマンドを組み合わせて自動化の仕組みを作ってくれる。しかもファイル操作、API呼び出し、データ変換あたりは得意分野だ。

この半年で5つの業務自動化レシピを作った。どれも「毎週やってるけど面倒」な作業を、Claude Codeに相談しながらスクリプトに落としたものだ。この記事では、そのうち3つのレシピの考え方とアプローチを紹介する。

---

## レシピ1：請求書PDFからの自動データ抽出

### 毎月の地味な苦行

月末になると取引先から請求書が届く。PDF、Excel、たまにスキャン画像。これをひとつずつ開いて、会社名・金額・支払期日を会計ソフトに手入力する。10社くらいなら耐えられるが、20社を超えると半日つぶれる。

### アプローチ

Claude Codeに相談して作ったのは、PDFを読み取ってCSVに変換するPythonスクリプトだ。

考え方はシンプルで、PDFからテキストを抽出し、LLMに構造化データとして整理させる。請求書のフォーマットが会社ごとにバラバラでも、LLMが文脈を読んで項目を特定してくれるのが強い。正規表現だけでやろうとすると、レイアウトが変わるたびに書き直しになる。

```python
import pdfplumber
from anthropic import Anthropic

def extract_invoice_data(pdf_path: str) -> dict:
    with pdfplumber.open(pdf_path) as pdf:
        text = "\n".join(page.extract_text() for page in pdf.pages)

    client = Anthropic()
    response = client.messages.create(
        model="claude-haiku-4-5",
        messages=[{"role": "user", "content": f"以下の請求書から情報を抽出...\n{text}"}],
    )
    return parse_response(response)
```

ポイントは3つある。

**pdfplumberでテキスト抽出。** PyPDF2よりもテーブル構造の認識が正確で、請求明細の行がきれいに取れる。

**Haikuで十分。** 請求書の構造化は比較的単純なタスクなので、Claude Haikuで速度とコストを抑える。月100件処理してもAPI費用は数百円程度。

**バリデーション層を挟む。** LLMの出力をそのまま信用しない。金額が数値か、日付がISO形式か、必須項目が揃っているかをチェックする関数を通す。ここを雑にするとあとで痛い目に遭う。

---

## レシピ2：問い合わせフォーム対応の自動ドラフト生成

### 同じ返信を何度も書いている

自社のWebサイトに問い合わせフォームがある。内容はだいたいパターンがあって、料金について、対応範囲について、スケジュールについて。毎回ゼロから書いているわけではないが、過去メールからコピペして調整して、という流れが1件あたり10〜15分かかる。週に5件来れば1時間。

### アプローチ

問い合わせ内容をカテゴリ分類し、テンプレートとFAQデータを組み合わせて返信ドラフトを自動生成する仕組みを作った。

```python
def classify_and_draft(inquiry: str, faq_data: list[dict]) -> str:
    # 1. 問い合わせを分類
    category = classify_inquiry(inquiry)
    # 2. 該当FAQを検索
    relevant = [f for f in faq_data if f["category"] == category]
    # 3. ドラフト生成
    return generate_reply(inquiry, relevant, tone="polite_business")
```

ここで重要なのはドラフトの位置づけだ。全自動で送信はしない。あくまでドラフトを生成して、人間が確認してから送る。

理由は単純で、問い合わせには微妙なニュアンスがある。「急ぎで」と書いてあったら優先度を上げたいし、既存クライアントからの追加相談なら文面のトーンも変わる。LLMはそういう背景を完全には読めない。

ただ、ゼロから書く手間が消えるだけで体感は全然違う。ドラフトを3行直して送信。これだけで1件2〜3分まで短縮できた。

もうひとつの工夫は、送信済みの返信をフィードバックとしてFAQデータに追記するループだ。「こう直した」という修正履歴がたまっていくと、次のドラフトの精度が勝手に上がる。

---

## レシピ3：定例レポートの自動生成

### 毎週金曜のルーティン

週次の稼働報告をクライアントに出す仕事がある。GitHub IssueとProjectのデータを集めて、今週やったこと・来週やること・課題をまとめる。内容は全部GitHubに書いてあるのに、それを整形してWordやMarkdownにする手作業が毎回30分。

### アプローチ

`gh` CLIでGitHub ProjectsのデータをJSON取得し、LLMに週次レポートの構成で整形させる。

```python
import subprocess, json

def fetch_completed_issues(project_id: str, since: str) -> list:
    result = subprocess.run(
        ["gh", "project", "item-list", project_id, "--format", "json"],
        capture_output=True, text=True,
    )
    items = json.loads(result.stdout)["items"]
    return [i for i in items if i["status"] == "Done" and i["updatedAt"] >= since]
```

このスクリプト単体は地味だが、価値はパイプラインとしてつなげたときに出る。

1. `gh` CLIで今週のDoneタスクと進行中タスクを取得
2. 各IssueのコメントやPRリンクから詳細を収集
3. LLMが週次レポートのフォーマットに整形
4. Markdownとして出力（必要ならdocxに変換）

元データがGitHub上に構造化されているので、LLMの仕事は整形だけ。ハルシネーションのリスクが低い。事実ベースの報告書には向いている手法だ。

---

## 残りの2レシピと全体設計

ここまでで3つ紹介した。残り2つは以下のようなテーマになる。

- **議事録からのアクションアイテム自動抽出と担当者振り分け** ― 音声文字起こし→LLM要約→GitHub Issue自動作成の流れ
- **営業リストの自動リサーチとアウトリーチ文面生成** ― ターゲット企業のWeb情報を収集し、パーソナライズした連絡文を下書き

どのレシピにも共通する設計思想がある。

### 完全自動化は目指さない

LLMを業務自動化に使うときの鉄則は「ドラフト生成＋人間レビュー」のパターンに落とすことだ。全自動にすると、LLMが変な出力をしたときのリカバリーコストが高い。ドラフト生成なら、おかしかったら直せばいいだけ。

### 小さく始める

最初からパイプライン全体を設計しない。まず一番面倒な1ステップだけ自動化する。請求書なら「PDFからテキスト抽出して金額を出す」だけでいい。そこが動いたら次のステップを足す。Claude Codeと対話しながらだと、この進め方が自然にできる。

### Claude Codeの使いどころ

Claude Codeが特に強いのは、APIのつなぎ込みとデータ変換の部分だ。

「GitHub APIからこういうデータを取って、こういう形式に変換して、Anthropic APIに投げて、結果をCSVに書き出して」

こういう指示を出すと、必要なライブラリのインストールからコードの実装、動作確認まで一気にやってくれる。自分がやるのは、業務フローの説明と出力結果の確認だけだ。

カスタムスキルとして保存しておけば、スラッシュコマンド一発で同じ自動化を何度でも回せる。この仕組みについては以前の記事で書いた。

---

## まとめ

5つのレシピの共通点を整理するとこうなる。

| 観点 | 方針 |
|------|------|
| 自動化の範囲 | 全自動ではなくドラフト生成＋人間レビュー |
| LLMの役割 | データの構造化・分類・整形が中心 |
| 入力データ | 構造化されたソース（PDF、API、DB）を優先 |
| コスト | Haikuメインで月額数千円に収める |
| 保守 | Claude Codeに修正を頼めるので属人化しにくい |

小さい会社だからこそ、少ない工数で効果が出る自動化がある。RPAや高額SaaSに手を出す前に、Claude Code＋Pythonスクリプトで十分なケースは思った以上に多い。

---

全5レシピの完全なコード付き解説は、noteの有料記事で公開しています。各レシピのエラーハンドリング、本番運用で踏んだ落とし穴、プロンプトの全文など、この記事では省略した実装の詳細をすべて載せています。
